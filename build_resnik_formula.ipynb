{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b> I. HPO metrics <br> </b>\n",
    "<b> II.Orpha - HPOs<br> </b>\n",
    "<b> III. Patients - HPO<br> </b>\n",
    "<b> IV. Count HPOs per patient and HPOs per Orpha<br> </b>\n",
    "<b> V Build the df frequence of HPOs orphacode <br> </b>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_of_ancestor(str_sentence):\n",
    "    \"\"\"\n",
    "    From : {HPOTerm(id='HP:0011804'\", \" name='Abnormal muscle physiology'\",\" is_a=['HP:0003011 ! Abnormality of the musculature'])\",\" HPOTerm(id='HP:0040064'\",\" name='Abnormality of limbs'\",\n",
    "    ...\n",
    "    to :\n",
    "      {'HP:0000001': 'is_a=[])', 'HP:0011804': 'HP:0003011', 'HP:0040064': 'HP:0000118', 'HP:0000118': 'HP:0000001', 'HP:0003011': 'HP:0033127', 'HP:0033127': 'HP:0000118', 'HP:0001324': 'HP:0011804'}\n",
    "      \n",
    "    From str into dict \n",
    "\n",
    "    \"\"\"\n",
    "    ancertor_dict = {}\n",
    "    one_split = str(str_sentence).split(',')\n",
    "    is_a = id = \"\"\n",
    "    for one_el in one_split:\n",
    "        #print(one_el)\n",
    "        if \"HPOTerm\" in one_el:\n",
    "            #print(one_el)\n",
    "            id = one_el.split(\"id='\")[1].replace(\"'\",'')\n",
    "        elif \"name=\" in one_el:\n",
    "            #print('Name : {}'.format(one_el))\n",
    "            pass\n",
    "        elif \"is_a=\" in one_el:\n",
    "            #print('is_a : {}'.format(one_el))\n",
    "            is_a_unstruct = one_el.replace(\"is_a=['\",'')\n",
    "            is_a = is_a_unstruct.split(\"!\")[0].strip()\n",
    "        ancertor_dict[id] = is_a\n",
    "    return ancertor_dict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Least commons ancestor\n",
    "def get_deepest_ancestor(str_sentence_common_ancestor):\n",
    "    \"\"\" \n",
    "        trouver l'ancetre commun le plus profond en evalue chaque clé valeur\n",
    "        il faut que la clé (enfant) ne se retrouve pas dans la valeur du dict (parent)\n",
    "        From dict to list\n",
    "        from :{'HP:0000001': 'is_a=[])', 'HP:0011804': 'HP:0003011', 'HP:0040064': 'HP:0000118', 'HP:0000118': 'HP:0000001', 'HP:0003011': 'HP:0033127', 'HP:0033127': 'HP:0000118', 'HP:0001324': 'HP:0011804'}\n",
    "        key : chilren, value : ancester\n",
    "        to :['HP:0040064', 'HP:0001324']\n",
    "    \"\"\"\n",
    "    ancertor_dict = get_parent_of_ancestor(str_sentence_common_ancestor)\n",
    "    #print(\"AC dict \\n : {}\".format(ancertor_dict))\n",
    "    list_LCAs = []  \n",
    "    for key in ancertor_dict.keys():\n",
    "        if key not in list(ancertor_dict.values()):\n",
    "            #print(\"one LCA : {}\".format(key))\n",
    "            list_LCAs.append(key)\n",
    "    return list_LCAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracts_LCAdescendant(hpo_LCA,orphacode_item_dict):\n",
    "    \"\"\" From the LCA found all it descendant\"\"\"\n",
    "\n",
    "    ## Extrait tout les descendants a partir du LCA \n",
    "\n",
    "    # extrait tout les LCAs trouver\n",
    "    all_LCA = []\n",
    "    all_LCA.append(hpo_LCA)\n",
    "    #print(all_LCA)\n",
    "\n",
    "    for oneLCA in all_LCA:\n",
    "        #print(oneLCA)\n",
    "        # parcourt l'onthology et extrait les enfants \n",
    "        list_child = Ontology.get_hpo_object(oneLCA).children\n",
    "        # parcourt les enfants\n",
    "        for one_children in list_child:\n",
    "            if one_children.id not in all_LCA: # si le descendant n'est pas dans la liste de tout les LCAs\n",
    "                if orphacode_item_dict[one_children.id] != 0: # si le nombre d'occurence est diff de 0 donc non present dans la base \n",
    "                    all_LCA.append(one_children.id) \n",
    "                    #print(\"len child {}\\t id:{}\\tnb occu: {}\".format(len(list_child),one_children.id,orphacode_dict[one_children.id]))\n",
    "    return all_LCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enumerated_LCAdescents_per_disease(all_LCA_desd,orphacode_dict):\n",
    "    \"\"\" From  all hpos LCA end their descendant count the disease where its appear\"\"\"\n",
    "    ## pour le LCA et ses descendants on regarde le nombre de maladies ou ils sont presents \n",
    "    orpha_LCAs = set()\n",
    "\n",
    "    for one_orpha in orphacode_dict.keys(): \n",
    "        # parcourt en premier tout les orpha\n",
    "        for onehpochild in all_LCA_desd:\n",
    "            # pour chaque orpha on regarde si le LCA et ses descants sont present \n",
    "            if onehpochild in orphacode_dict[one_orpha]:\n",
    "                # si l'hpo est present on incremente la liste de la maladie\n",
    "                orpha_LCAs.add(one_orpha)\n",
    "    return orpha_LCAs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export in txt frmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(path, d_list,str_name):\n",
    "    with open(path +\"\\\\\" + str_name + \".txt\", 'a') as f:\n",
    "\n",
    "        for oneel in d_list:\n",
    "            # we use ; to split because it's esier to handle \n",
    "            f.write(str(oneel) + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### librairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # use to extrat nb of hpo from hpo.json\n",
    "from pyhpo import stats, Ontology, HPOSet,term # hpo3\n",
    "import xmltodict # for the orphcode pd4\n",
    "import collections # for count nb of hpo in patient or orphacode\n",
    "import os \n",
    "import math # for the log to get the IC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_projet = r\"C:\\Users\\mchahdil\\Desktop\\compare_study\\\\\"\n",
    "path_input = path_projet + r\"\\input_files\\\\\"\n",
    "path_output = path_projet + r\"\\output_files\\\\\"\n",
    "\n",
    "\n",
    "path_phenopacket = r\"C:\\Users\\mchahdil\\Desktop\\data_patient\\json_raw\\\\\"\n",
    "path_orpha = path_input+r'\\orphanet_files'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. HPO metric \n",
    "\n",
    "<b> rsd: 16614 terms</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load hpo3 : </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17059"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyhpo import Ontology\n",
    "#Ontology(path_hpo+\"/ontology/\")\n",
    "Ontology()\n",
    "\n",
    "i=0\n",
    "# iterating all HPO terms\n",
    "for term in Ontology:\n",
    "    #print(term.name)\n",
    "    i=i+1\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.Orpha - HPOs <br>\n",
    "<b>  rsd : 4210 terms </b><br>\n",
    "We set IC of these to : 8.345217926676428 = -1 * (log(1 / 4210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orphacode_info=dict()\n",
    "all_hpo_orphacode = []\n",
    "with open(path_orpha+'/en_product4.xml') as pd_xml:\n",
    "    root = xmltodict.parse(pd_xml.read())\n",
    "xml_dict = root['JDBOR']['HPODisorderSetStatusList']['HPODisorderSetStatus']\n",
    "for one_dict in xml_dict:\n",
    "    hpo_list = []\n",
    "    section_disorder = one_dict['Disorder']\n",
    "    #print(section_disorder['OrphaCode'])\n",
    "    section_hpo = section_disorder['HPODisorderAssociationList']\n",
    "    #print(section_hpo.keys())\n",
    "    # because sometime HPODisorderAssociation dict don't exist \n",
    "    if \"HPODisorderAssociation\" in section_hpo.keys():    \n",
    "        for one_hpodict in section_hpo['HPODisorderAssociation']:\n",
    "            hpo_id = one_hpodict['HPO']['HPOId']\n",
    "            hpo_list.append(hpo_id)\n",
    "            all_hpo_orphacode.append(hpo_id)\n",
    "    orphacode_info[section_disorder['OrphaCode']] = set(hpo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4242"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orphacode_info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  III. Patients - HPOs\n",
    "#### Get Solved case confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 patients solved confirmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mchahdil\\AppData\\Local\\miniconda3\\envs\\tuto_website\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pd_phenopacket_confirmed = pd.read_excel(path_input + \"/PATIENTS SOLVED_FC_v1.xlsx\",engine='openpyxl',sheet_name='Feuil2')\n",
    "pd_phenopacket_confirmed = pd_phenopacket_confirmed[pd_phenopacket_confirmed['Result'] == \"yes\"]\n",
    "patients_c = pd_phenopacket_confirmed['Patient ID'].drop_duplicates().tolist()\n",
    "\n",
    "print(\"{} patients solved confirmed\".format(len(patients_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path patients\n",
    "files_json = os.listdir(path_phenopacket)\n",
    " \n",
    "# remove the desktop.ini' and keep only phenopackets\n",
    "patients_json = []\n",
    "for op in files_json:\n",
    "    # select only patients solved confirmed\n",
    "    op_split= op.split('.')[0]\n",
    "    if op_split in patients_c:\n",
    "        patients_json.append(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patientsinfo = dict()\n",
    "all_hpo_patients = []\n",
    "\n",
    "pheno_with_invalid_id =set()\n",
    "empty_no_phenotypic_feature = set()\n",
    "for onep in patients_json:\n",
    "    id_list = []\n",
    "    with open(path_phenopacket+str(\"\\\\\"+onep),'r',encoding = 'utf8') as file_phenopacket:\n",
    "        one_result = json.load(file_phenopacket)\n",
    "\n",
    "        one_phenopacket_result = one_result['phenopacket']\n",
    "        id_phenopacket = one_phenopacket_result['id']\n",
    "        # phenotypicFeatures dict key store hpo\n",
    "        if 'phenotypicFeatures' in one_phenopacket_result.keys():\n",
    "            #  list_hpo contains all HPO terms\n",
    "            list_hpo = one_phenopacket_result['phenotypicFeatures']\n",
    "\n",
    "            if not bool(list_hpo):\n",
    "                # if this list is empty\n",
    "                empty_no_phenotypic_feature.add(id_phenopacket)\n",
    "            else :\n",
    "                hpo_temp = []\n",
    "                for onehpo in list_hpo:\n",
    "                    if not bool(onehpo):\n",
    "                        # sometime it s like this  [{}] ... list filled with en empty dict !\n",
    "                        empty_no_phenotypic_feature.add(id_phenopacket)\n",
    "                    else:\n",
    "                        # fill the hpo_temp list\n",
    "                        try:\n",
    "                            if ((\"Invalid id\" == onehpo['type.label'])):\n",
    "                                pheno_with_invalid_id.add(id_phenopacket)\n",
    "                                pass\n",
    "                            if ( 'type.negated' not in onehpo.keys()):\n",
    "                                hpo_temp.append(onehpo['type.id'])\n",
    "                                all_hpo_patients.append(onehpo['type.id'])\n",
    "\n",
    "                        except KeyError:\n",
    "                            # json format dict may also have this structure : label and not type.label\n",
    "\n",
    "                            if ((\"Invalid id\" == onehpo['type']['label']) ):\n",
    "                                pheno_with_invalid_id.add(id_phenopacket) \n",
    "                                pass\n",
    "                            if ( 'negated' not in onehpo.keys()):\n",
    "                                hpo_temp.append(onehpo['type']['id'])\n",
    "                                all_hpo_patients.append(onehpo['type']['id'])\n",
    "\n",
    "\n",
    "                if len(hpo_temp) >= 5:\n",
    "                    if ((id_phenopacket not in pheno_with_invalid_id) and (id_phenopacket not in empty_no_phenotypic_feature)):\n",
    "                        # if the number of element in hpo_temp is hight than 5 then the phenopacket contains more than 5HPO\n",
    "                        patientsinfo[id_phenopacket] = hpo_temp\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV Count HPOs per patient and HPOs per Orpha\n",
    "Compte la fréquence d'apparition des HPO dans les patients puis dans les orphacode\n",
    "pd deux dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count HPO per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_hpo_item = collections.Counter(all_hpo_patients)\n",
    "len(patientsinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nb of different type HPO \n",
    "len(patient_hpo_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count HPO per Orphacode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphacode_hpo_item = collections.Counter(all_hpo_orphacode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of hpo tot sans doublons\n",
    "tot_nb_items_hpo_orphacode = sum(list(orphacode_hpo_item.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb hpo all : 111765\tnb hpo unique : 8305\tnb disease : 4242\n"
     ]
    }
   ],
   "source": [
    "#nb of different type HPO \n",
    "print('nb hpo all : {}\\tnb hpo unique : {}\\tnb disease : {}'.format(tot_nb_items_hpo_orphacode,len(orphacode_hpo_item),len(orphacode_info)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V Build the df IC of all hpo in orphanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of HPO available in Orphanet : 8305\n"
     ]
    }
   ],
   "source": [
    "# from collection dict type to list \n",
    "orphacode_hpo_list = list(orphacode_hpo_item.keys())\n",
    "print('nb of HPO available in Orphanet : {}'.format(len(orphacode_hpo_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dict for each hpo get theirs descants and counts occurend of those hpo in orphanet disease \n",
    "<br> (plus simple apres plus besoin de calculer a chaque fois on va utiliser ce dictionnaire plutot qui est calculer une fois )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP:0001578 Unknown HPO term\n",
      "HP:0200115 Unknown HPO term\n",
      "HP:4000141 Unknown HPO term\n"
     ]
    }
   ],
   "source": [
    "dict_hpo_ic = {}\n",
    "for onehpo in orphacode_hpo_list:\n",
    "    try :\n",
    "        all_LCA = extracts_LCAdescendant(onehpo,orphacode_hpo_item)\n",
    "        #print(\"Le nb de LCA et ses descendants : {}\".format(len(all_LCA)))\n",
    "\n",
    "        orpha_LCAs = enumerated_LCAdescents_per_disease(all_LCA,orphacode_info)\n",
    "        numerator_ic = len(orpha_LCAs)\n",
    "        #print('Nb of diseases annotated with LCA and theirs descendant : {}'.format(numerator_ic) )\n",
    "\n",
    "        ic = -math.log(len(orpha_LCAs) / len(orphacode_info))\n",
    "        #print(\"IC : {}\".format(ic))\n",
    "        dict_hpo_ic[onehpo] = [ic,numerator_ic]\n",
    "    except RuntimeError:\n",
    "        print(\"{} Unknown HPO term\".format(onehpo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This hpo HP:0007210 should be 4,52 : [4.524148738635533, 46]\n",
      "This hpo HP:0000924 should be 0,49 : [0.4914483395246388, 2595]\n"
     ]
    }
   ],
   "source": [
    "### verication with know ic (cf script  whhy_not_the_same.ipynb\n",
    "print(\"This hpo HP:0007210 should be 4,52 : {}\".format(dict_hpo_ic['HP:0007210']))\n",
    "print(\"This hpo HP:0000924 should be 0,49 : {}\".format(dict_hpo_ic['HP:0000924']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI Resnik similarity for patient - orpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construction d'une boucle pour chaque patient et pour chacun de ses HPO on va les confrontée avec tout les HPO de la maladies donc pour le second HPO du patient on confront encore tout les HPO de la maladie ect... \n",
    "- donc pour chaque hpo patient vs tout les hpo maladie on regarde l'ancetre commun le plus proche \n",
    "- puis on calcul le IC donc resnik (qui est obtenu via le dict)\n",
    "- pour chaque pair d'hpo patient -maladie on selectionne le LCA qui a un ic le plus haut  \n",
    "\n",
    "- quand on construit la df resnik  on fait la somme de tout les resnik obtenu et on divise par le nombre de hpo du patient \n",
    "\n",
    "<br><br>\n",
    "exemple : \n",
    " \n",
    "HPO patients                                                    LE HPO ORPHA qui a le max rensik                           resnik\n",
    "Somatic sensory dysfunction (HP:0003474)                     Absent Achilles reflex (HP:0003438)                          0.38                                                        \n",
    "Distal upper limb amyotrophy (HP:0007149)                    Intrinsic hand muscle atrophy (HP:0008954)                   4.66                                                        \n",
    "Distal lower limb amyotrophy (HP:0008944)                    Intrinsic hand muscle atrophy (HP:0008954)                   3.73                                                        \n",
    "Distal upper limb muscle weakness (HP:0008959)               Tibialis muscle weakness (HP:0008963)                        3.48                                                        \n",
    "Proximal muscle weakness in lower limbs (HP:0008994)         Progressive proximal muscle weakness (HP:0009073)            3.51                                                        \n",
    "Distal lower limb muscle weakness (HP:0009053)               Tibialis muscle weakness (HP:0008963)                        4.28                                                        \n",
    "Progressive proximal muscle weakness (HP:0009073)            Progressive proximal muscle weakness (HP:0009073)            5.40                                                        \n",
    "sum 25.44 div by 7 = 3.63 (returned value)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the LCA and its calculated the IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_interractions_hpo = set()\n",
    "all_detail_interactions = []\n",
    "\n",
    "hpo_not_use_in_orphacode = []\n",
    "hpo_no_AC_common = []\n",
    "hpo_unkown = []\n",
    "for one_patient in patientsinfo.keys():\n",
    "    #if one_patient == \"P0001068\" : \n",
    "        # get the HPO list of the patient of interest\n",
    "        hpo_list_POF = patientsinfo[one_patient]\n",
    "        #hpo_list_POF = ['HP:0040068'] # 0007149 0040068\n",
    "\n",
    "        for one_orpha in orphacode_info.keys():\n",
    "            #if i <=600: #i <=20 : #one_orpha == \"324442\" : 178400  \n",
    "                \n",
    "                # ge the HPO list of the orpha curently tested\n",
    "                hpo_list_OOI = orphacode_info[one_orpha]\n",
    "                #hpo_list_OOI = ['HP:0011842'] # 0003438 \n",
    "\n",
    "                for onehpo_p in hpo_list_POF:\n",
    "                    # dict to store the resnik sim of each hpo from orphacode BASED ON A SINGLE HPO PATIENT\n",
    "                    hpo_ooi_LCA_resnik = {}\n",
    "                    try :\n",
    "                        ### get the type HPOTerm for hpo3 library\n",
    "                        term_patient = Ontology.get_hpo_object(onehpo_p)\n",
    "\n",
    "                        for onehpo_o in hpo_list_OOI:\n",
    "                            \"\"\" on a besoin de toutes ces sim pour en selectionner un seul et faire la meme chose pour \n",
    "                                tout les hpo des patients \"\"\"\n",
    "                        \n",
    "                            ### get the type HPOTerm for hpo3 library\n",
    "                            term_disease = Ontology.get_hpo_object(onehpo_o)\n",
    "                            \n",
    "                            #print(\"########################\")\n",
    "                            #print(\"Patient : {}\\t HPO patient:\\t{}\".format(one_patient,term_patient))\n",
    "                            #print(\"Orphacode : ORPHA:{}\\t HPO disease:\\t{}\".format(one_orpha,term_disease))\n",
    "\n",
    "                            ### Identification des Ancêtres Communs : \n",
    "                            all_common_ancestors = term_patient.common_ancestors(term_disease)\n",
    "\n",
    "                            # we have all the commons ancestor let get the closest which is the firt one in the set (converted in a list)\n",
    "                            if not list(all_common_ancestors):\n",
    "                                #print(\" cas pas d'ancetre commun retrouver (situation impossible)\")\n",
    "                                #excluded \n",
    "                                hpo_no_AC_common.append((one_patient,str(\"ORPHA:\"+one_orpha),term_patient.id,term_disease.id))\n",
    "\n",
    "                            else: \n",
    "                                ### get the lca based on the list of commons ancestor\n",
    "                                # contain the get_parent_of_ancestor function\n",
    "                                list_LCAs = get_deepest_ancestor(all_common_ancestors) \n",
    "                                #print(\"LCAs : {}\".format(list_LCAs))\n",
    "\n",
    "                                for id_LCA in list_LCAs:\n",
    "                                    try : \n",
    "                                        resnik = dict_hpo_ic[id_LCA][0]\n",
    "                                        all_detail_interactions.append((one_patient,str(\"ORPHA:\"+one_orpha),term_patient.id,term_disease.id,\n",
    "                                                                                                        id_LCA,dict_hpo_ic[id_LCA][1],resnik))     \n",
    "                                        # for each hpo FROM ORPHACODE and the hpo for patient get the LCA and store its resnik\n",
    "                                        hpo_ooi_LCA_resnik[term_disease.id] = [resnik,id_LCA]\n",
    "\n",
    "\n",
    "                                    except KeyError:\n",
    "                                        # This HPO is not use in the Orphanet ontho\n",
    "                                        hpo_not_use_in_orphacode.append(id_LCA)\n",
    "                                        # set resnik the same as rsd set it \n",
    "                                        resnik = -math.log(1 / 4210)\n",
    "                                        hpo_ooi_LCA_resnik[term_disease.id] = [resnik,id_LCA]\n",
    "\n",
    "                                                                \n",
    "\n",
    "                                    \n",
    "                                    \n",
    "                                # one the dict is build we extract the max resnik\n",
    "                                max_resnik_disease_hpo = max(hpo_ooi_LCA_resnik, key=hpo_ooi_LCA_resnik.get)\n",
    "                                max_resnik_disease_hpo_sim = hpo_ooi_LCA_resnik[max_resnik_disease_hpo][0]\n",
    "                                max_resnik_disease_hpo_LCA = hpo_ooi_LCA_resnik[max_resnik_disease_hpo][1]\n",
    "\n",
    "                                all_interractions_hpo.add((one_patient,str(\"ORPHA:\"+one_orpha),term_patient.id,max_resnik_disease_hpo,max_resnik_disease_hpo_sim,max_resnik_disease_hpo_LCA))\n",
    "\n",
    "                    except RuntimeError:\n",
    "                        # unknow hpo terms\n",
    "                        # un des deux \n",
    "                        hpo_unkown.append((term_disease.id,term_patient.id))\n",
    "\n",
    "#df_hpo_no_AC_common = pd.DataFrame(hpo_no_AC_common, columns=[\"phenopacket\",'orphacode','HP_patient','HP_disease'])\n",
    "#detail_resnik_calcul = pd.DataFrame(all_detail_interactions, columns=[\"phenopacket\",'orphacode','HP_patient','HP_disease','HP_LCA',\"nb_times_LCA_in_orphanet\",'IC_LCA'])\n",
    "\n",
    "hpo_description = pd.DataFrame(all_interractions_hpo, columns=[\"phenopacket\",'orphacode','HP_patient','HP_max_LCA','resnik','HP_LCA'])\n",
    "# remove all row with HP:0000001 in the hpo_description\n",
    "hpo_description_f= hpo_description[~hpo_description['HP_LCA'].str.contains(\"HP:0000001\")]\n",
    "\n",
    "##################\n",
    "print(\"UNKNOWN  HPO {}\".format(len(set(hpo_unkown))))\n",
    "#print(\"No common_ancestors between HPO disease and HPO patient  {}\".format(len(df_hpo_no_AC_common.drop_duplicates())))\n",
    "print(\"HPO not in the Orphanet onthology   {}\".format(len(set(hpo_not_use_in_orphacode))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minidf = hpo_description_f[hpo_description_f[\"orphacode\"] == \"ORPHA:192\" ]\n",
    "#minidf.to_excel(path_output+\"hpo_description.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try to undestands why hpo dont have ancestor in commons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_hpo_no_AC_common "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verif common ancestor\n",
    "# term_patient = Ontology.get_hpo_object(\"HP:0003701\")\n",
    "# term_disease = Ontology.get_hpo_object(\"HP:0040073\")\n",
    "\n",
    "# term_patient.common_ancestors(term_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcul Resnik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_pheno= hpo_description_f['phenopacket'].drop_duplicates().to_list()\n",
    "list_df_orpha= hpo_description_f['orphacode'].drop_duplicates().to_list()\n",
    "\n",
    "all_interaction_resnik = []\n",
    "for onephenopacket in list_df_pheno:\n",
    "    # split the df by patients\n",
    "    mini_df= hpo_description_f[hpo_description_f['phenopacket']== onephenopacket]\n",
    "    \n",
    "    for oneorphacode in list_df_orpha:\n",
    "        # split by orpha\n",
    "        mini_mini_df= mini_df[mini_df['orphacode']==oneorphacode]\n",
    "        # get unique LCA from this interactions \n",
    "        all_hpoLCA = mini_mini_df['HP_LCA'].drop_duplicates()\n",
    "        # smerge all ic and divided by the number of LCA found for this orpha\n",
    "        sum_ic = 0\n",
    "        for oneLCA in all_hpoLCA:\n",
    "            sum_ic = sum_ic + dict_hpo_ic[oneLCA][0]\n",
    "        final_ic = sum_ic / len(all_hpoLCA)\n",
    "\n",
    "        all_interaction_resnik.append((onephenopacket,oneorphacode,final_ic))\n",
    " \n",
    "df_resnik = pd.DataFrame(all_interaction_resnik, columns=[\"phenopacket\",'ORPHAcode','resnik'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etablir le rank cad pour chaque maladie garder uniquement le top 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P0001068':      phenopacket     ORPHAcode    resnik\n",
       " 2255    P0001068   ORPHA:98856  3.002744\n",
       " 3578    P0001068   ORPHA:98897  2.991674\n",
       " 1681    P0001068   ORPHA:63273  2.925893\n",
       " 3047    P0001068  ORPHA:101097  2.901952\n",
       " 1613    P0001068  ORPHA:178400  2.897214\n",
       " 1242    P0001068   ORPHA:98912  2.894281\n",
       " 2826    P0001068     ORPHA:610  2.862502\n",
       " 2190    P0001068   ORPHA:99953  2.860372\n",
       " 257     P0001068  ORPHA:435387  2.859376\n",
       " 1896    P0001068  ORPHA:466768  2.811051\n",
       " 2875    P0001068  ORPHA:399086  2.809856\n",
       " 177     P0001068  ORPHA:101077  2.798716\n",
       " 281     P0001068  ORPHA:254361  2.780477\n",
       " 2813    P0001068   ORPHA:99956  2.751191\n",
       " 1444    P0001068   ORPHA:99947  2.732660\n",
       " 82      P0001068  ORPHA:399103  2.732213\n",
       " 28      P0001068  ORPHA:276435  2.729070\n",
       " 392     P0001068  ORPHA:482601  2.719368\n",
       " 904     P0001068  ORPHA:457050  2.684322\n",
       " 3134    P0001068  ORPHA:497764  2.674840\n",
       " 2055    P0001068   ORPHA:90103  2.672626\n",
       " 56      P0001068  ORPHA:101076  2.667706\n",
       " 1991    P0001068  ORPHA:101085  2.648809\n",
       " 4156    P0001068   ORPHA:99950  2.648600\n",
       " 3266    P0001068     ORPHA:609  2.631848\n",
       " 313     P0001068   ORPHA:45448  2.625640\n",
       " 1006    P0001068     ORPHA:602  2.616481\n",
       " 2067    P0001068   ORPHA:79093  2.611368\n",
       " 1510    P0001068  ORPHA:100991  2.582432\n",
       " 2686    P0001068     ORPHA:603  2.574748\n",
       " 2179    P0001068  ORPHA:488333  2.554596\n",
       " 1741    P0001068  ORPHA:399096  2.545116\n",
       " 2337    P0001068   ORPHA:98911  2.538075\n",
       " 84      P0001068    ORPHA:2596  2.533208\n",
       " 675     P0001068   ORPHA:98909  2.520300\n",
       " 315     P0001068      ORPHA:70  2.518742\n",
       " 1946    P0001068  ORPHA:399081  2.513451\n",
       " 3278    P0001068  ORPHA:171706  2.507627\n",
       " 357     P0001068   ORPHA:99944  2.499100\n",
       " 1031    P0001068     ORPHA:268  2.497122\n",
       " 2077    P0001068  ORPHA:488650  2.493211\n",
       " 2274    P0001068  ORPHA:171617  2.487249\n",
       " 844     P0001068  ORPHA:320375  2.484755\n",
       " 1173    P0001068     ORPHA:598  2.463543\n",
       " 1627    P0001068  ORPHA:206549  2.427093\n",
       " 2207    P0001068  ORPHA:254875  2.417120\n",
       " 3519    P0001068  ORPHA:399058  2.416501\n",
       " 2572    P0001068  ORPHA:206569  2.411913\n",
       " 433     P0001068   ORPHA:90658  2.407619\n",
       " 1266    P0001068  ORPHA:363623  2.402964}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construiction a partir de la df resnik d'un dict de df \n",
    "list_df_pheno= df_resnik['phenopacket'].drop_duplicates().to_list()\n",
    "list_df_orpha= df_resnik['ORPHAcode'].drop_duplicates().to_list()\n",
    "\n",
    "all_interaction_resnik = []\n",
    "dict_of_resnik_df = {}\n",
    "\n",
    "for onephenopacket in list_df_pheno:\n",
    "    # split the df by patients\n",
    "    mini_df= df_resnik[df_resnik['phenopacket']== onephenopacket]\n",
    "    # sort by score\n",
    "    df_op = mini_df.sort_values('resnik',ascending=False)\n",
    "    # keep the top 50\n",
    "    df_op = df_op.head(50)\n",
    "    df_op.reset_index(drop=True)\n",
    "    dict_of_resnik_df[onephenopacket] = df_op\n",
    "\n",
    "    df_op= pd.DataFrame([], columns=[\"phenopacket\",'ORPHAcode','resnik'])\n",
    "\n",
    "\n",
    "dict_of_resnik_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenopacket</th>\n",
       "      <th>ORPHAcode</th>\n",
       "      <th>resnik</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:98856</td>\n",
       "      <td>3.002744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:98897</td>\n",
       "      <td>2.991674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:63273</td>\n",
       "      <td>2.925893</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:101097</td>\n",
       "      <td>2.901952</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:178400</td>\n",
       "      <td>2.897214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:98912</td>\n",
       "      <td>2.894281</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:610</td>\n",
       "      <td>2.862502</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:99953</td>\n",
       "      <td>2.860372</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:435387</td>\n",
       "      <td>2.859376</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:466768</td>\n",
       "      <td>2.811051</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:399086</td>\n",
       "      <td>2.809856</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:101077</td>\n",
       "      <td>2.798716</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:254361</td>\n",
       "      <td>2.780477</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:99956</td>\n",
       "      <td>2.751191</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:99947</td>\n",
       "      <td>2.732660</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:399103</td>\n",
       "      <td>2.732213</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:276435</td>\n",
       "      <td>2.729070</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:482601</td>\n",
       "      <td>2.719368</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:457050</td>\n",
       "      <td>2.684322</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:497764</td>\n",
       "      <td>2.674840</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:90103</td>\n",
       "      <td>2.672626</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:101076</td>\n",
       "      <td>2.667706</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:101085</td>\n",
       "      <td>2.648809</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:99950</td>\n",
       "      <td>2.648600</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:609</td>\n",
       "      <td>2.631848</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:45448</td>\n",
       "      <td>2.625640</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:602</td>\n",
       "      <td>2.616481</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:79093</td>\n",
       "      <td>2.611368</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:100991</td>\n",
       "      <td>2.582432</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:603</td>\n",
       "      <td>2.574748</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:488333</td>\n",
       "      <td>2.554596</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:399096</td>\n",
       "      <td>2.545116</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:98911</td>\n",
       "      <td>2.538075</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:2596</td>\n",
       "      <td>2.533208</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:98909</td>\n",
       "      <td>2.520300</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:70</td>\n",
       "      <td>2.518742</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:399081</td>\n",
       "      <td>2.513451</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:171706</td>\n",
       "      <td>2.507627</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:99944</td>\n",
       "      <td>2.499100</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:268</td>\n",
       "      <td>2.497122</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:488650</td>\n",
       "      <td>2.493211</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:171617</td>\n",
       "      <td>2.487249</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:320375</td>\n",
       "      <td>2.484755</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:598</td>\n",
       "      <td>2.463543</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:206549</td>\n",
       "      <td>2.427093</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:254875</td>\n",
       "      <td>2.417120</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:399058</td>\n",
       "      <td>2.416501</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:206569</td>\n",
       "      <td>2.411913</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:90658</td>\n",
       "      <td>2.407619</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>P0001068</td>\n",
       "      <td>ORPHA:363623</td>\n",
       "      <td>2.402964</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phenopacket     ORPHAcode    resnik  rank\n",
       "0     P0001068   ORPHA:98856  3.002744     1\n",
       "1     P0001068   ORPHA:98897  2.991674     2\n",
       "2     P0001068   ORPHA:63273  2.925893     3\n",
       "3     P0001068  ORPHA:101097  2.901952     4\n",
       "4     P0001068  ORPHA:178400  2.897214     5\n",
       "5     P0001068   ORPHA:98912  2.894281     6\n",
       "6     P0001068     ORPHA:610  2.862502     7\n",
       "7     P0001068   ORPHA:99953  2.860372     8\n",
       "8     P0001068  ORPHA:435387  2.859376     9\n",
       "9     P0001068  ORPHA:466768  2.811051    10\n",
       "10    P0001068  ORPHA:399086  2.809856    11\n",
       "11    P0001068  ORPHA:101077  2.798716    12\n",
       "12    P0001068  ORPHA:254361  2.780477    13\n",
       "13    P0001068   ORPHA:99956  2.751191    14\n",
       "14    P0001068   ORPHA:99947  2.732660    15\n",
       "15    P0001068  ORPHA:399103  2.732213    16\n",
       "16    P0001068  ORPHA:276435  2.729070    17\n",
       "17    P0001068  ORPHA:482601  2.719368    18\n",
       "18    P0001068  ORPHA:457050  2.684322    19\n",
       "19    P0001068  ORPHA:497764  2.674840    20\n",
       "20    P0001068   ORPHA:90103  2.672626    21\n",
       "21    P0001068  ORPHA:101076  2.667706    22\n",
       "22    P0001068  ORPHA:101085  2.648809    23\n",
       "23    P0001068   ORPHA:99950  2.648600    24\n",
       "24    P0001068     ORPHA:609  2.631848    25\n",
       "25    P0001068   ORPHA:45448  2.625640    26\n",
       "26    P0001068     ORPHA:602  2.616481    27\n",
       "27    P0001068   ORPHA:79093  2.611368    28\n",
       "28    P0001068  ORPHA:100991  2.582432    29\n",
       "29    P0001068     ORPHA:603  2.574748    30\n",
       "30    P0001068  ORPHA:488333  2.554596    31\n",
       "31    P0001068  ORPHA:399096  2.545116    32\n",
       "32    P0001068   ORPHA:98911  2.538075    33\n",
       "33    P0001068    ORPHA:2596  2.533208    34\n",
       "34    P0001068   ORPHA:98909  2.520300    35\n",
       "35    P0001068      ORPHA:70  2.518742    36\n",
       "36    P0001068  ORPHA:399081  2.513451    37\n",
       "37    P0001068  ORPHA:171706  2.507627    38\n",
       "38    P0001068   ORPHA:99944  2.499100    39\n",
       "39    P0001068     ORPHA:268  2.497122    40\n",
       "40    P0001068  ORPHA:488650  2.493211    41\n",
       "41    P0001068  ORPHA:171617  2.487249    42\n",
       "42    P0001068  ORPHA:320375  2.484755    43\n",
       "43    P0001068     ORPHA:598  2.463543    44\n",
       "44    P0001068  ORPHA:206549  2.427093    45\n",
       "45    P0001068  ORPHA:254875  2.417120    46\n",
       "46    P0001068  ORPHA:399058  2.416501    47\n",
       "47    P0001068  ORPHA:206569  2.411913    48\n",
       "48    P0001068   ORPHA:90658  2.407619    49\n",
       "49    P0001068  ORPHA:363623  2.402964    50"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_interractions=[]\n",
    "\n",
    "\n",
    "for key,dfval in dict_of_resnik_df.items():\n",
    "    #print(\"set the df for the patient {}\".format(key))\n",
    "    dict_df_one_P_hpo3 = dfval.to_dict('index')\n",
    "\n",
    "    i = 0 # for the rank\n",
    "    for value in dict_df_one_P_hpo3.values():\n",
    "        hpo3_onepheno = value['phenopacket']\n",
    "        hpo3_oneorpha= value['ORPHAcode']\n",
    "        hpo3_onescore= value['resnik']\n",
    "\n",
    "        i = i + 1\n",
    "        \n",
    "        all_interractions.append((hpo3_onepheno,hpo3_oneorpha,hpo3_onescore,i))\n",
    "\n",
    "\n",
    "\n",
    "df_resnik_with_rank = pd.DataFrame(all_interractions, columns=[\"phenopacket\",'ORPHAcode','resnik','rank'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noneIC = detail_resnik_calcul2[detail_resnik_calcul2[\\'HP_patient\\'] == \"HP:0008959\"][\\'IC_ancestor\\'][1]\\nprint(oneIC)\\n#10puissance (-IC)\\nprint(10**(-oneIC))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = own formula, 3 own formula with IC hpo3\n",
    "# 1 = own CUM  formula, 4 own  CUM formula with IC hpo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_OI = \"P0001068\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_resnik_with_rank.to_excel(path_output+\"df_resnik_with_rank.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpo_no_AC_common= df_hpo_no_AC_common.drop_duplicates()\n",
    "df_hpo_no_AC_common.to_excel(path_output+str(patient_OI)+\"_resnik_no_common_ancestor.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file(path_output, list(set(hpo_unkown)),str(patient_OI)+\"_resnik_unknowHPO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file(path_output, list(set(hpo_not_use_in_orphacode)),str(patient_OI)+\"_resnik_not_in_orphanet_HPO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apporter leur exp dans les taches que le doctorant doit effectué, corriger si besoin, laisser le doctorant suivre ses pistes (souvent pas bonne)\n",
    "Avancement dans les problematiques en lien avec la these, recherche biblo, se poser les bonne questions,\n",
    "Produire une cohérence dans le travail et les taches effectué\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuto_website",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
